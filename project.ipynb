{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEMO for Test Time Adaptation\n",
    "TODO: insert short intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "TODO with bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3ImageFolder(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.s3_bucket = \"deeplearning2024-datasets\"\n",
    "        self.s3_region = \"eu-west-1\"\n",
    "        self.s3_client = boto3.client(\"s3\", region_name=self.s3_region, verify=True)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Get list of objects in the bucket\n",
    "        response = self.s3_client.list_objects_v2(Bucket=self.s3_bucket, Prefix=root)\n",
    "        objects = response.get(\"Contents\", [])\n",
    "        while response.get(\"NextContinuationToken\"):\n",
    "            response = self.s3_client.list_objects_v2(\n",
    "                Bucket=self.s3_bucket,\n",
    "                Prefix=root,\n",
    "                ContinuationToken=response[\"NextContinuationToken\"]\n",
    "            )\n",
    "            objects.extend(response.get(\"Contents\", []))\n",
    "\n",
    "        # Iterate and keep valid files only\n",
    "        self.instances = []\n",
    "        for ds_idx, item in enumerate(objects):\n",
    "            key = item[\"Key\"]\n",
    "            path = Path(key)\n",
    "\n",
    "            # Check if file is valid\n",
    "            if path.suffix.lower() not in (\".jpg\", \".jpeg\", \".png\", \".ppm\", \".bmp\", \".pgm\", \".tif\", \".tiff\", \".webp\"):\n",
    "                continue\n",
    "\n",
    "            # Get label\n",
    "            label = path.parent.name\n",
    "\n",
    "            # Keep track of valid instances\n",
    "            self.instances.append((label, key))\n",
    "\n",
    "        # Sort classes in alphabetical order (as in ImageFolder)\n",
    "        self.classes = sorted(set(label for label, _ in self.instances))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.instances)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            label, key = self.instances[idx]\n",
    "\n",
    "            # Download image from S3\n",
    "            # response = self.s3_client.get_object(Bucket=self.s3_bucket, Key=key)\n",
    "            # img_bytes = response[\"Body\"]._raw_stream.data\n",
    "\n",
    "            img_bytes = BytesIO()\n",
    "            response = self.s3_client.download_fileobj(Bucket=self.s3_bucket, Key=key, Fileobj=img_bytes)\n",
    "            # img_bytes = response[\"Body\"]._raw_stream.data\n",
    "\n",
    "            # Open image with PIL\n",
    "            img = Image.open(img_bytes).convert(\"RGB\")\n",
    "\n",
    "            # Apply transformations if any\n",
    "            if self.transform is not None:\n",
    "                img = self.transform(img)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading image at index {idx}: {str(e)}\")\n",
    "\n",
    "        return img, self.class_to_idx[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, img_root):\n",
    "    # Prepare data transformations for the train loader\n",
    "    transform = T.Compose([\n",
    "        T.Resize((256, 256)),                                                   # Resize each PIL image to 256 x 256\n",
    "        T.RandomCrop((224, 224)),                                               # Randomly crop a 224 x 224 patch\n",
    "        T.ToTensor(),                                                           # Convert Numpy to Pytorch Tensor\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),      # Normalize with ImageNet mean\n",
    "\n",
    "        #Â ViT_B_16_Weights.DEFAULT.transforms()        # TODO: is this correct here?\n",
    "    ])\n",
    "\n",
    "    # Load data\n",
    "    # officehome_dataset = ImageFolder(root=img_root, transform=transform)\n",
    "    dataset = S3ImageFolder(root=img_root, transform=transform)\n",
    "\n",
    "    # Create train and test splits (80/20)\n",
    "    num_samples = len(dataset)\n",
    "    training_samples = int(num_samples * 0.8 + 1)\n",
    "    test_samples = num_samples - training_samples\n",
    "\n",
    "    training_data, test_data = torch.utils.data.random_split(dataset, [training_samples, test_samples])\n",
    "\n",
    "    # Initialize dataloaders\n",
    "    train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/Memo_DL2024/project.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://xgtk4hmbmy2qdfw.studio.eu-west-1.sagemaker.aws/home/sagemaker-user/Memo_DL2024/project.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m mean \u001b[39m=\u001b[39m [\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://xgtk4hmbmy2qdfw.studio.eu-west-1.sagemaker.aws/home/sagemaker-user/Memo_DL2024/project.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m std \u001b[39m=\u001b[39m [\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell://xgtk4hmbmy2qdfw.studio.eu-west-1.sagemaker.aws/home/sagemaker-user/Memo_DL2024/project.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m test_transform \u001b[39m=\u001b[39m trn\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m      <a href='vscode-notebook-cell://xgtk4hmbmy2qdfw.studio.eu-west-1.sagemaker.aws/home/sagemaker-user/Memo_DL2024/project.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     [trn\u001b[39m.\u001b[39mResize(\u001b[39m256\u001b[39m), trn\u001b[39m.\u001b[39mCenterCrop(\u001b[39m224\u001b[39m), trn\u001b[39m.\u001b[39mToTensor(), trn\u001b[39m.\u001b[39mNormalize(mean, std)])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trn' is not defined"
     ]
    }
   ],
   "source": [
    "# from https://github.com/hendrycks/natural-adv-examples/blob/master/eval.py\n",
    "\n",
    "# adversarial samples\n",
    "\n",
    "import torchvision.transforms as trn\n",
    "\n",
    "thousand_k_to_200 = {}\n",
    "indices_in_1k = [k for k in thousand_k_to_200 if thousand_k_to_200[k] != -1]\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "test_transform = trn.Compose(\n",
    "    [trn.Resize(256), trn.CenterCrop(224), trn.ToTensor(), trn.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "ViT-b/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "\n",
    "weights = ViT_B_16_Weights.DEFAULT\n",
    "# preprocess = weights.transforms()\n",
    "\n",
    "model = vit_b_16(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    return vit_b_16(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO make as function\n",
    "\n",
    "class MarginalEntropy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, outputs):\n",
    "        # compute mean entropy\n",
    "        logits = outputs - outputs.logsumexp(dim=-1, keepdim=True)\n",
    "        avg_logits = logits.logsumexp(dim=0) - np.log(logits.shape[0])\n",
    "        min_real = torch.finfo(avg_logits.dtype).min\n",
    "        avg_logits = torch.clamp(avg_logits, min=min_real)\n",
    "        mean_entropy = -(avg_logits * torch.exp(avg_logits)).sum(dim=-1), avg_logits\n",
    "        return mean_entropy\n",
    "\n",
    "loss_fn = MarginalEntropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentations for MEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://github.com/google-research/augmix\n",
    "\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "preaugment = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "])\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "def _augmix_aug(x_orig):\n",
    "    x_orig = preaugment(x_orig)\n",
    "    x_processed = preprocess(x_orig)\n",
    "    w = np.float32(np.random.dirichlet([1.0, 1.0, 1.0]))\n",
    "    m = np.float32(np.random.beta(1.0, 1.0))\n",
    "\n",
    "    mix = torch.zeros_like(x_processed)\n",
    "    for i in range(3):          # repeat process\n",
    "        x_aug = x_orig.copy()\n",
    "        for _ in range(np.random.randint(1, 4)):            # how many filter apply\n",
    "            x_aug = np.random.choice(augmentations)(x_aug)  # pick randomly\n",
    "        mix += w[i] * preprocess(x_aug)     # multiply by a magnitude ??\n",
    "    mix = m * x_processed + (1 - m) * mix\n",
    "    return mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, cost_function, device=\"cuda\"):\n",
    "    model.eval()\n",
    "\n",
    "    samples = 0.0\n",
    "    cumulative_loss = 0.0\n",
    "    cumulative_accuracy = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = cost_function(outputs, targets)\n",
    "\n",
    "            samples += inputs.shape[0]\n",
    "            cumulative_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            cumulative_accuracy += predicted.eq(targets).sum().item()\n",
    "\n",
    "    return cumulative_loss / samples, cumulative_accuracy / samples * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memo_tta(pretrained_model, sample, epochs_for_adaptation, augmentations):\n",
    "    optimizer = torch.optim.SGD(pretrained_model.parameters(), lr=learning_rate)\n",
    "\n",
    "    augmented_samples = []\n",
    "    \n",
    "    # TODO how to parallelize this\n",
    "    for augmentation in augmentations:\n",
    "        augmented_sample = augmentation(sample)\n",
    "        augmented_samples.append(augmented_sample[0])\n",
    "    augmented_samples = torch.stack(augmented_samples)\n",
    "\n",
    "    pretrained_model.eval()\n",
    "    for epoch in range(epochs_for_adaptation):\n",
    "        output_distributions = pretrained_model(augmented_samples)\n",
    "        output_distributions = output_distributions[:, indices_in_1k]\n",
    "    \n",
    "        loss, _ = loss_fn(output_distributions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # TODO Adapting BN statistics, maybe in adapt_single()\n",
    "    \n",
    "    return pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_ROOT = \"imagenet-a/\"\n",
    "BATCH_SIZE = 32  # TODO: to change?\n",
    "\n",
    "train_loader, test_loader = get_data(BATCH_SIZE, IMG_ROOT)\n",
    "\n",
    "cost_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "loss, accuracy = test(model, test_loader, cost_function, device=\"cpu\")\n",
    "print(loss, accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of: test time adaptation via MEMO\n",
    "\n",
    "# \"only one gradient step per test point\" as per paper\n",
    "epochs_for_adaptation = 1\n",
    "\n",
    "correct_predictions = 0\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    \n",
    "    # input_image = sample[0].unsqueeze(0)  # create a mini-batch as expected by the resnet model\n",
    "    # # todo, are the labels in the same order as the output classes from the model?\n",
    "    # input_label = sample[1]\n",
    "\n",
    "    # pretrained_model = get_fresh_pretrained_model()\n",
    "\n",
    "    pretrained_model = init_vit_b()\n",
    "    adapted_model = memo_tta(pretrained_model, input_image, epochs_for_adaptation)\n",
    "\n",
    "    # inference phase\n",
    "    # todo change prior_strength\n",
    "    prediction = test_single(adapted_model, input_image, -1)\n",
    "    correctness = 1 if prediction == input_label else 0\n",
    "    correct_predictions += correctness"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
